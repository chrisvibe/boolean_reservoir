logging:
  out_path: out/temporal/density/grid_search/heterogeneous-stochastic
  grid_search:
    seed: 0
    n_samples: 10
  save_keys: [parameters]
model:
  input_layer:
    bits_per_feature: 1
    distribution: identity
    connection: [out-0:b:1/b, out-1:b:1/b] # Iâ†’R mapping: stochastic out-degree
    encoding: base2
    interleaving: 0
    features: 10
    pertubation: [override, xor]
    redundancy: 1
    w_in: null
  output_layer:
    activation: sigmoid
    n_outputs: 1
  reservoir_layer:
    init: [zeros, random]
    k_avg: [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9, 7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 8.0, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9.0, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9, 10.0]
    k_min: 0
    k_max: 25
    mode: heterogeneous
    n_nodes: 500
    p: 0.5
    reset: true
    self_loops: null
  training:
    accuracy_threshold: 0.5
    batch_size: 100
    criterion: BCE
    epochs: 40
    evaluation: dev
    learning_rate: 0.001
dataset:
  task: density
  bit_stream_length: 10
  window_size: 3
  tao: [3, 5, 7]
  split:
    train: 0.4
    dev: 0.3
    test: 0.3
  samples: 10000
  seed: 0