logging:
  history:
    buffer_size: 64
    record_history: True
  out_path: out/temporal/reservoir/kq_and_gr/heterogenous
model:
  input_layer:
    bits_per_feature: 1
    distribution: identity
    connection: out-0:b:1/(a+b) # "I additional input nodes that distribute the input signals to the nodes in the network. The source node of Ki links for each node i is randomly picked from N + I nodes with uniform probability" (their N is my R)
    encoding: base2
    interleaving: 0
    features: 10
    n_nodes: 10
    # pertubation: override
    pertubation: [override, xor]
    redundancy: 1
    w_in: null
  output_layer:
    activation: sigmoid
    n_outputs: 1
  reservoir_layer:
    # init: zeros # deduced from figure 1A as the rank is near zero at k=0, with random init the KQ and GR rank would start high 
    init: [zeros, random]
    k_avg: [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9, 7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 8.0, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9.0, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9, 10.0] # only for heterogenous
    k_min: 0
    k_max: 20
    mode: heterogenous
    n_nodes: 25
    p: 0.5
    reset: true # essentially KQ == GR if false
    # reset: [true, false]
    self_loops: null
  training:
    accuracy_threshold: 0.5
    batch_size: 100
    criterion: BCE
    epochs: 40
    evaluation: dev
    learning_rate: 0.001
dataset:
  task: density # not really just using the x values and ignoring y
  bit_stream_length: 10
  window_size: 3 # not using this
  tao: 2 # controls tao for KQ and GR instead of tao for temporal denisty task (bits overriden to make similar inputs)
  split: # not training the model, just recording state changes with input
    train: 1
    dev: 0
    test: 0
  samples: 100 # overriden so we get samples equal to number of reservoir nodes (square matrix) * number of models seeds (each model gets a set)