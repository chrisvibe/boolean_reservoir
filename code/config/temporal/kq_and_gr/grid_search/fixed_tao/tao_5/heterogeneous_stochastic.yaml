logging:
  history:
    buffer_size: 64
    record_history: True
  out_path: out/temporal/kq_and_gr/grid_search/heterogeneous-stochastic-tao5
  save_keys: null
model:
  input_layer:
    w_bi: identity
    w_ir: [out-0:b:1/b, out-1:b:1/b] # Iâ†’R mapping: stochastic out-degree
    encoding: base2
    interleaving: 0
    features: 10
    pertubation: [override, xor]
    redundancy: 1
    resolution: 1
    w_in: null
  output_layer:
    activation: sigmoid
    n_outputs: 1
  reservoir_layer:
    init: [zeros, random]
    k_avg: [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9, 7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 8.0, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9.0, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9, 10.0]
    k_min: 0
    k_max: 25
    mode: heterogeneous
    n_nodes: 25
    p: 0.5
    reset: true
    self_loops: null
  training:
    accuracy_threshold: 0.5
    batch_size: 100
    criterion: BCE
    epochs: 40
    evaluation: dev
dataset: # this whole section is repurposed to control the custom experiments
  task: density # not really just using the x values and ignoring y
  bit_stream_length: 10
  window_size: 3 # not using this
  tao: 5 # controls tao for KQ and GR instead of tao for temporal density task (bits overriden to make similar inputs)
  split: # not training the model, just recording state changes with input
    train: 1
    dev: 0
    test: 0
  samples: 25 # number of samples/random seeds per configuration. overwritten by code so we get samples equal to number of reservoir nodes (square matrix) * number of models seeds (each model gets a set)